# Datasets and Preprocessing

At first, each member of the team had to find datasets to match the perspectives for our research. During the first team call, every dataset was discussed along with possible correlations. In the end, we chose the ... datasets from Kaggle to start, as these datasets have correlations that could be of use for a potential topic. After some brainstorming during team meetings, we came to the conclusion to focus on the welbeing of citizens in Europian capitals, as the datasets contain sufficient variables that can be used for two perspectives: 'influences of economic prosperity' and 'influences of environmental prosperity'.

During our project, we encountered new insights and, after consulting with our TA, decided to look for additional datasets. For our project, we primarily focused on the correlation of various variables with the happiness score, as it provided an indication of the well-being of people within a particular city.

#### Cleaning

We had to go through two phases in order to clean everything properly. At first we renamed columns and restructured them to merge them together. We manually merged the columns by inspecting them and merging the ones that contained roughly the same content. We excluded Columns that were not of use.

The second phase involves normalising the data. In general, this has been done by thoroughly inspecting the unique values for each column and combine values that represent similar meaning.

We decided to use CSV as the file type for our final datasets. This allowed us to create a well organized set. It resulted in a ...MB CSV file, rather than a ...MB CSV file.

It resluted several sets. One has a total of ...columns spanning ... datasets that have been reduced to a single dataset containing ... columns and ... rows and another that has ...columns and ... rows.
